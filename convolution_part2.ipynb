{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_cuda_alex",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyoti246/alexnet_cuda_cudnn/blob/main/Final_cuda_alex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgoVCDff0W3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWCWu0xfgLLP",
        "outputId": "2e68e8ed-2ac7-4369-bbbf-6b052a394d76"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhfZWV24gNSp",
        "outputId": "17143af2-7c8b-42e9-d270-9b5efdcd1b41"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-r_1z_r2o\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-r_1z_r2o\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.7/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=9dbaaab517354efc2000cbe8207d26bc1443be41c4188414760c4841feb54147\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3p_15plg/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvCEbLSAgNol",
        "outputId": "6812ef60-a629-4135-a93d-8d2fb443a087"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DdZn_1otgUON",
        "outputId": "ac33b8f2-a142-4f9b-9c73-08d434260a08"
      },
      "source": [
        "%%cuda --name alex.cu\n",
        "#include <cudnn.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdlib>\n",
        "#include <cassert>\n",
        "#include <cstdlib>\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "#include <random>\n",
        "#include <cmath>\n",
        "#include <stdio.h>\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define BATCH_SIZE 8\n",
        "#define MAX_THREADS_PER_BLOCK 1024 // according to GTX 1050 Ti\n",
        "\n",
        "int roundUp(int num, int den)\n",
        "{\n",
        "\n",
        "  return((num + den - 1 )/(den));\n",
        "\n",
        "}\n",
        "\n",
        "struct convDim_t{\n",
        "\n",
        "  int Height;\n",
        "  int Width;\n",
        "  int Channels;\n",
        "  int Batch;\n",
        "};\n",
        "\n",
        "struct kernelDim_t{\n",
        "\n",
        "  int kernelSize;\n",
        "  int kernelHeight;\n",
        "  int kernelWidth;\n",
        "  int strideHeight;\n",
        "  int strideWidth;\n",
        "  int padHeight;\n",
        "  int padWidth;\n",
        "  int dilationHeight;\n",
        "  int dilationWidth;\n",
        "};\n",
        "\n",
        "\n",
        "convDim_t setConvSpecs(int ht, int wd, int ch, int bt){\n",
        "\n",
        "  convDim_t temp;\n",
        "  temp.Height = ht;\n",
        "  temp.Width = wd;\n",
        "  temp.Channels = ch;\n",
        "  temp.Batch = bt;\n",
        "\n",
        "  return temp;\n",
        "}\n",
        "\n",
        "kernelDim_t setKernelSpecs(int size, int fheight, int fwidth, int sheight, int swidth, int pheight, int pwidth, int dheight, int dwidth){\n",
        "\n",
        "  kernelDim_t layerKernel;\n",
        "  layerKernel.kernelSize = size;\n",
        "  layerKernel.kernelHeight = fheight;\n",
        "  layerKernel.kernelWidth = fwidth;\n",
        "  layerKernel.strideHeight = sheight;\n",
        "  layerKernel.strideWidth = swidth;\n",
        "  layerKernel.padHeight = pheight;\n",
        "  layerKernel.padWidth = pwidth;\n",
        "  layerKernel.dilationHeight = dheight;\n",
        "  layerKernel.dilationWidth = dwidth;\n",
        "\n",
        "  return layerKernel;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#define checkCUDNN(expression)                             \\\n",
        "{                                                          \\\n",
        "  cudnnStatus_t status = (expression);                     \\\n",
        "  if (status != CUDNN_STATUS_SUCCESS) {                    \\\n",
        "    std::cerr << \"Error on line \" << __LINE__ << \": \"      \\\n",
        "              << cudnnGetErrorString(status) << std::endl; \\\n",
        "    std::exit(EXIT_FAILURE);                               \\\n",
        "  }                                                        \\\n",
        "}\n",
        "\n",
        "\n",
        "float alpha = 1.0;\n",
        "float beta = 0.0;\n",
        "\n",
        "class ConvLayers{\n",
        "    \n",
        "public:\n",
        "    float *kernelTensor{nullptr};\t\t\n",
        "    int layerIndex;\n",
        "\t  size_t workspace_bytes{0};\n",
        "\n",
        "    convDim_t outDims;\n",
        "    convDim_t inDims;\n",
        "    kernelDim_t kernelDims;\n",
        "\t    \n",
        "\n",
        "    cudnnTensorDescriptor_t input_descriptor;\n",
        "    cudnnTensorDescriptor_t output_descriptor;\n",
        "    cudnnFilterDescriptor_t kernel_descriptor;\n",
        "    cudnnConvolutionDescriptor_t convolution_descriptor;\n",
        "    cudnnConvolutionFwdAlgo_t convolution_algorithm;\n",
        "\n",
        "    ConvLayers(){}\n",
        "\n",
        "    ConvLayers(int index, convDim_t inDim, kernelDim_t kdims, convDim_t outDims){\n",
        "\n",
        "      this->inDims = inDim;\n",
        "      this->kernelDims = kdims;\n",
        "      this->layerIndex = index;\n",
        "\t    this->outDims = outDims;\n",
        "    }\n",
        "\n",
        "    void buildConvLayer();\n",
        "\n",
        "    void fwdProp(cudaStream_t stream, cudnnHandle_t cudnn, float *inputTensor, float* &outputTensor, void* &d_workspace);\n",
        "\n",
        "};\n",
        "\n",
        "void ConvLayers::buildConvLayer(){\n",
        "\tcheckCUDNN(cudnnCreateTensorDescriptor(&input_descriptor));\n",
        "\tcheckCUDNN(cudnnSetTensor4dDescriptor(input_descriptor,\n",
        "\t\t\t\t\t\t\t\t\t\t/*format=*/CUDNN_TENSOR_NHWC,\n",
        "\t\t\t\t\t\t\t\t\t\t/*dataType=*/CUDNN_DATA_FLOAT,\n",
        "\t\t\t\t\t\t\t\t\t\t/*batch_size=*/inDims.Batch,\n",
        "\t\t\t\t\t\t\t\t\t\t/*channels=*/inDims.Channels,\n",
        "\t\t\t\t\t\t\t\t\t\t/*image_height=*/inDims.Height,\n",
        "\t\t\t\t\t\t\t\t\t\t/*image_width=*/inDims.Width));\n",
        "\n",
        "\n",
        "\n",
        "\tcheckCUDNN(cudnnCreateTensorDescriptor(&output_descriptor));\n",
        "\tcheckCUDNN(cudnnSetTensor4dDescriptor(output_descriptor,\n",
        "\t\t\t\t\t\t\t\t\t\t/*format=*/CUDNN_TENSOR_NHWC,\n",
        "\t\t\t\t\t\t\t\t\t\t/*dataType=*/CUDNN_DATA_FLOAT,\n",
        "\t\t\t\t\t\t\t\t\t\t/*batch_size=*/outDims.Batch,\n",
        "\t\t\t\t\t\t\t\t\t\t/*channels=*/outDims.Channels,\n",
        "\t\t\t\t\t\t\t\t\t\t/*image_height=*/outDims.Height,\n",
        "\t\t\t\t\t\t\t\t\t\t/*image_width=*/outDims.Width));   \n",
        "\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\t\t\t\t\n",
        "\n",
        "\tcheckCUDNN(cudnnCreateFilterDescriptor(&kernel_descriptor));\n",
        "\tcheckCUDNN(cudnnSetFilter4dDescriptor(kernel_descriptor,\n",
        "\t\t\t\t\t\t\t\t\t\t/*dataType=*/CUDNN_DATA_FLOAT,\n",
        "\t\t\t\t\t\t\t\t\t\t/*format=*/CUDNN_TENSOR_NCHW,\n",
        "\t\t\t\t\t\t\t\t\t\t/*out_channels=*/outDims.Channels,\n",
        "\t\t\t\t\t\t\t\t\t\t/*in_channels=*/inDims.Channels,\n",
        "\t\t\t\t\t\t\t\t\t\t/*kernel_height=*/kernelDims.kernelHeight,\n",
        "\t\t\t\t\t\t\t\t\t\t/*kernel_width=*/kernelDims.kernelWidth)); \n",
        "\t\t\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\t\t\t\t\n",
        "\n",
        "\tcheckCUDNN(cudnnCreateConvolutionDescriptor(&convolution_descriptor));\n",
        "\tcheckCUDNN(cudnnSetConvolution2dDescriptor(convolution_descriptor,\n",
        "\t\t\t\t\t\t\t\t\t\t/*pad_height=*/kernelDims.padHeight,\n",
        "\t\t\t\t\t\t\t\t\t\t/*pad_width=*/kernelDims.padWidth,\n",
        "\t\t\t\t\t\t\t\t\t\t/*vertical_stride=*/kernelDims.strideHeight,\n",
        "\t\t\t\t\t\t\t\t\t\t/*horizontal_stride=*/kernelDims.strideWidth,\n",
        "\t\t\t\t\t\t\t\t\t\t/*dilation_height=*/kernelDims.dilationHeight,\n",
        "\t\t\t\t\t\t\t\t\t\t/*dilation_width=*/kernelDims.dilationWidth,\n",
        "\t\t\t\t\t\t\t\t\t\t/*mode=*/CUDNN_CROSS_CORRELATION,\n",
        "\t\t\t\t\t\t\t\t\t\t/*computeType=*/CUDNN_DATA_FLOAT));\n",
        "\n",
        "\n",
        "\tfloat h_kernel[outDims.Channels][inDims.Channels][kernelDims.kernelHeight][kernelDims.kernelWidth];\n",
        "    for (int kernel = 0; kernel < outDims.Channels; ++kernel) {\n",
        "    for (int channel = 0; channel < inDims.Channels; ++channel) {\n",
        "        for (int row = 0; row < kernelDims.kernelHeight; ++row) {\n",
        "        for (int column = 0; column < kernelDims.kernelWidth; ++column) {\n",
        "            h_kernel[kernel][channel][row][column] = 0.5;\n",
        "        }\n",
        "        }\n",
        "    }\n",
        "    }\n",
        "\n",
        "    cudaMalloc(&kernelTensor, sizeof(h_kernel));\n",
        "    cudaMemcpy(kernelTensor, h_kernel, sizeof(h_kernel), cudaMemcpyHostToDevice); \n",
        "}\n",
        "\n",
        "\n",
        "void ConvLayers::fwdProp(cudaStream_t stream, cudnnHandle_t cudnn, float *inputTensor, float* &outputTensor, void* &d_workspace)\n",
        "{\n",
        "\tcheckCUDNN(cudnnGetConvolutionForwardAlgorithm(cudnn,\n",
        "                                            input_descriptor,\n",
        "                                            kernel_descriptor,\n",
        "                                            convolution_descriptor,\n",
        "                                            output_descriptor,\n",
        "                                            CUDNN_CONVOLUTION_FWD_PREFER_FASTEST,\n",
        "                                            /*memoryLimitInBytes=*/0,\n",
        "                                            &convolution_algorithm));\n",
        "                                            \n",
        "\n",
        "    checkCUDNN(cudnnGetConvolutionForwardWorkspaceSize(cudnn,\n",
        "                                                    input_descriptor,\n",
        "                                                    kernel_descriptor,\n",
        "                                                    convolution_descriptor,\n",
        "                                                    output_descriptor,\n",
        "                                                    convolution_algorithm,\n",
        "                                                    &workspace_bytes));                  \n",
        "                \n",
        "    cudaMalloc(&d_workspace, workspace_bytes);       \n",
        "\n",
        "\tint out_bytes = outDims.Batch*outDims.Channels*outDims.Height*outDims.Width*sizeof(float);\n",
        "    cudaMalloc(&outputTensor, out_bytes);\n",
        "    cudaMemsetAsync(outputTensor, 0, out_bytes, stream);\n",
        "\n",
        "\n",
        "    checkCUDNN(cudnnConvolutionForward(cudnn,\n",
        "                                   &alpha,\n",
        "                                   input_descriptor,\n",
        "                                   inputTensor,\n",
        "                                   kernel_descriptor,\n",
        "                                   kernelTensor,\n",
        "                                   convolution_descriptor,\n",
        "                                   convolution_algorithm,\n",
        "                                   d_workspace,\n",
        "                                   workspace_bytes,\n",
        "                                   &beta,\n",
        "                                   output_descriptor,\n",
        "                                   outputTensor));\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void call_conv1(ConvLayers &convlayer1, cudaStream_t stream, cudnnHandle_t CUDNN, float input[][224][224][3], float output[1][224][224][10])\n",
        "{\n",
        "    float *inputTensor;\n",
        "\tfloat *outputTensor;\n",
        "\tint inp_size = convlayer1.inDims.Height * convlayer1.inDims.Width * convlayer1.inDims.Channels * convlayer1.inDims.Batch * sizeof(float);\n",
        "    cudaMalloc(&inputTensor, inp_size);\n",
        "    cudaMemcpyAsync(inputTensor, input, inp_size, cudaMemcpyHostToDevice, stream);\n",
        "\n",
        "    void *d_workspace;\n",
        "    convlayer1.fwdProp(stream, CUDNN, inputTensor, outputTensor, d_workspace);\n",
        "\n",
        "    int out_size =  convlayer1.outDims.Height*convlayer1.outDims.Width*convlayer1.outDims.Channels*convlayer1.outDims.Batch*sizeof(float);\n",
        "    \n",
        "    cudaMemcpyAsync(output, outputTensor, out_size, cudaMemcpyDeviceToHost, stream);\n",
        "\n",
        "    //cout << \"CONV1 DONE\" << endl;\n",
        "}\n",
        "\n",
        "void call_conv2(ConvLayers &convlayer1, cudaStream_t stream, cudnnHandle_t CUDNN, float input[][224][224][10], float output[1][224][224][30])\n",
        "{\n",
        "    float *inputTensor;\n",
        "\tfloat *outputTensor;\n",
        "\tint inp_size = convlayer1.inDims.Height * convlayer1.inDims.Width * convlayer1.inDims.Channels * convlayer1.inDims.Batch * sizeof(float);\n",
        "    cudaMalloc(&inputTensor, inp_size);\n",
        "    cudaMemcpyAsync(inputTensor, input, inp_size, cudaMemcpyHostToDevice, stream);\n",
        "\n",
        "    void *d_workspace;\n",
        "    convlayer1.fwdProp(stream, CUDNN, inputTensor, outputTensor, d_workspace);\n",
        "\n",
        "    int out_size =  convlayer1.outDims.Height*convlayer1.outDims.Width*convlayer1.outDims.Channels*convlayer1.outDims.Batch*sizeof(float);\n",
        "    \n",
        "    cudaMemcpyAsync(output, outputTensor, out_size, cudaMemcpyDeviceToHost, stream);\n",
        "\n",
        "    //cout << \"CONV2 DONE\" << endl;\n",
        "}\n",
        "\n",
        "\n",
        "void call_conv3(ConvLayers &convlayer1, cudaStream_t stream, cudnnHandle_t CUDNN, float input[][224][224][30], float output[1][224][224][30])\n",
        "{\n",
        "    float *inputTensor;\n",
        "\tfloat *outputTensor;\n",
        "\tint inp_size = convlayer1.inDims.Height * convlayer1.inDims.Width * convlayer1.inDims.Channels * convlayer1.inDims.Batch * sizeof(float);\n",
        "    cudaMalloc(&inputTensor, inp_size);\n",
        "    cudaMemcpyAsync(inputTensor, input, inp_size, cudaMemcpyHostToDevice, stream);\n",
        "\n",
        "    void *d_workspace;\n",
        "    convlayer1.fwdProp(stream, CUDNN, inputTensor, outputTensor, d_workspace);\n",
        "\n",
        "    int out_size =  convlayer1.outDims.Height*convlayer1.outDims.Width*convlayer1.outDims.Channels*convlayer1.outDims.Batch*sizeof(float);\n",
        "    \n",
        "    cudaMemcpyAsync(output, outputTensor, out_size, cudaMemcpyDeviceToHost, stream);\n",
        "\n",
        "    //cout << \"CONV3 DONE\" << endl;\n",
        "}\n",
        "\n",
        "void call_conv4(ConvLayers &convlayer1, cudaStream_t stream, cudnnHandle_t CUDNN, float input[][224][224][30], float output[1][224][224][10])\n",
        "{\n",
        "    float *inputTensor;\n",
        "\tfloat *outputTensor;\n",
        "\tint inp_size = convlayer1.inDims.Height * convlayer1.inDims.Width * convlayer1.inDims.Channels * convlayer1.inDims.Batch * sizeof(float);\n",
        "    cudaMalloc(&inputTensor, inp_size);\n",
        "    cudaMemcpyAsync(inputTensor, input, inp_size, cudaMemcpyHostToDevice, stream);\n",
        "\n",
        "    void *d_workspace;\n",
        "    convlayer1.fwdProp(stream, CUDNN, inputTensor, outputTensor, d_workspace);\n",
        "\n",
        "    int out_size =  convlayer1.outDims.Height*convlayer1.outDims.Width*convlayer1.outDims.Channels*convlayer1.outDims.Batch*sizeof(float);\n",
        "    \n",
        "    cudaMemcpyAsync(output, outputTensor, out_size, cudaMemcpyDeviceToHost, stream);\n",
        "\n",
        "    //cout << \"CONV4 DONE\" << endl;\n",
        "}\n",
        "\n",
        "void call_conv5(ConvLayers &convlayer1, cudaStream_t stream, cudnnHandle_t CUDNN, float input[][224][224][10], float output[1][224][224][3])\n",
        "{\n",
        "    float *inputTensor;\n",
        "\tfloat *outputTensor;\n",
        "\tint inp_size = convlayer1.inDims.Height * convlayer1.inDims.Width * convlayer1.inDims.Channels * convlayer1.inDims.Batch * sizeof(float);\n",
        "    cudaMalloc(&inputTensor, inp_size);\n",
        "    cudaMemcpyAsync(inputTensor, input, inp_size, cudaMemcpyHostToDevice, stream);\n",
        "\n",
        "    void *d_workspace;\n",
        "    convlayer1.fwdProp(stream, CUDNN, inputTensor, outputTensor, d_workspace);\n",
        "\n",
        "    int out_size =  convlayer1.outDims.Height*convlayer1.outDims.Width*convlayer1.outDims.Channels*convlayer1.outDims.Batch*sizeof(float);\n",
        "    \n",
        "    cudaMemcpyAsync(output, outputTensor, out_size, cudaMemcpyDeviceToHost, stream);\n",
        "\n",
        "    //cout << \"CONV5 DONE\" << endl;\n",
        "}\n",
        "\n",
        "\n",
        "#define num_batches 2\n",
        "float img[num_batches][BATCH_SIZE][224][224][3];\n",
        "float output1[num_batches][BATCH_SIZE][224][224][10];\n",
        "float output2[num_batches][BATCH_SIZE][224][224][30];\n",
        "float output3[num_batches][BATCH_SIZE][224][224][30];\n",
        "float output4[num_batches][BATCH_SIZE][224][224][10];\n",
        "float output5[num_batches][BATCH_SIZE][224][224][3];\n",
        "\n",
        "void processImg(int index, cudaStream_t stream, cudnnHandle_t cudnn, ConvLayers &convlayer1, ConvLayers &convlayer2, ConvLayers &convlayer3, ConvLayers &convlayer4, ConvLayers &convlayer5)\n",
        "{\n",
        "\tcall_conv1(convlayer1, stream, cudnn, img[index], output1[index]);\n",
        "\tcall_conv2(convlayer2, stream, cudnn, output1[index], output2[index]);\n",
        "\tcall_conv3(convlayer3, stream, cudnn, output2[index], output3[index]);\n",
        "\tcall_conv4(convlayer4, stream, cudnn, output3[index], output4[index]);\n",
        "\tcall_conv5(convlayer5, stream, cudnn, output4[index], output5[index]);\n",
        "}\n",
        "\n",
        "//channel, height, width\n",
        "int main(){\n",
        "\tfor(int m=0;m<num_batches;++m){\n",
        "\t\tfor(int i=0;i<BATCH_SIZE;++i){\n",
        "\t\t\tfor(int j=0; j<224;++j){\n",
        "\t\t\t\tfor(int k=0;k<224;++k){\n",
        "\t\t\t\t\tfor(int l=0;l<3;++l){\n",
        "\t\t\t\t\t\timg[m][i][j][k][l]=0.001;\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tconvDim_t InputDims1 = setConvSpecs(224, 224, 3, BATCH_SIZE);\n",
        "\tkernelDim_t layerKernel1 = setKernelSpecs(0,3,3,1,1,1,1,1,1);\n",
        "\tconvDim_t OutputDims1 = setConvSpecs(224, 224, 10, BATCH_SIZE);\n",
        "\tConvLayers convlayer1(1, InputDims1, layerKernel1, OutputDims1);\n",
        "\tconvlayer1.buildConvLayer();\n",
        "\t\n",
        "\tconvDim_t InputDims2 = setConvSpecs(224, 224, 10, BATCH_SIZE);\n",
        "\tkernelDim_t layerKernel2 = setKernelSpecs(0,3,3,1,1,1,1,1,1);\n",
        "\tconvDim_t OutputDims2 = setConvSpecs(224, 224, 30, BATCH_SIZE);\n",
        "\tConvLayers convlayer2(2, InputDims2, layerKernel2, OutputDims2);\n",
        "\tconvlayer2.buildConvLayer();\n",
        "\n",
        "\tconvDim_t InputDims3 = setConvSpecs(224, 224, 30, BATCH_SIZE);\n",
        "\tkernelDim_t layerKernel3 = setKernelSpecs(0,3,3,1,1,1,1,1,1);\n",
        "\tconvDim_t OutputDims3 = setConvSpecs(224, 224, 30, BATCH_SIZE);\n",
        "\tConvLayers convlayer3(3, InputDims3, layerKernel3, OutputDims3);\n",
        "\tconvlayer3.buildConvLayer();\n",
        "\n",
        "\tconvDim_t InputDims4 = setConvSpecs(224, 224, 30, BATCH_SIZE);\n",
        "\tkernelDim_t layerKernel4 = setKernelSpecs(0,3,3,1,1,1,1,1,1);\n",
        "\tconvDim_t OutputDims4 = setConvSpecs(224, 224, 10, BATCH_SIZE);\n",
        "\tConvLayers convlayer4(4, InputDims4, layerKernel4, OutputDims4);\n",
        "\tconvlayer4.buildConvLayer();\n",
        "\n",
        "\tconvDim_t InputDims5 = setConvSpecs(224, 224, 10, BATCH_SIZE);\n",
        "\tkernelDim_t layerKernel5 = setKernelSpecs(0,3,3,1,1,1,1,1,1);\n",
        "\tconvDim_t OutputDims5 = setConvSpecs(224, 224, 3, BATCH_SIZE);\n",
        "\tConvLayers convlayer5(5, InputDims5, layerKernel5, OutputDims5);\n",
        "\tconvlayer5.buildConvLayer();\n",
        "  \n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  for(int nstreams=1; nstreams<=8;++nstreams)\n",
        "  {\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    \n",
        "    cudaStream_t stream[nstreams];\n",
        "    cudnnHandle_t cudnn[nstreams];\n",
        "    for(int i=0;i<nstreams;++i){\n",
        "      cudaStreamCreate(&stream[i]);\n",
        "      checkCUDNN(cudnnCreate(&cudnn[i]));\n",
        "      cudnnSetStream(cudnn[i], stream[i]);\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    for(int i=0;i<num_batches;++i)\n",
        "    {\n",
        "      cudaStreamSynchronize(stream[i%nstreams]);\n",
        "      processImg(i, stream[i%nstreams], cudnn[i%nstreams], convlayer1, convlayer2, convlayer3, convlayer4, convlayer5);\n",
        "      //cout<<\"Image \"<<i<<\" dispatched.\"<<endl;\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "   \n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float elapsedtime;\n",
        "    cudaEventElapsedTime(&elapsedtime, start, stop);\n",
        "    cout << \"Nstreams \"<<nstreams<<\"ELAPSED TIME: \" << elapsedtime << endl;\n",
        "  }\n",
        "\tcudaDeviceSynchronize();\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/alex.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HesrPiNCgBbh"
      },
      "source": [
        "!nvcc /content/src/alex.cu `pkg-config --cflags --libs opencv` -lcudnn -lcublas -lopencv_imgcodecs -lopencv_imgproc -lopencv_core -pg -std=c++11 -o /content/src/alex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPVm-7eygdVl",
        "outputId": "f14dbde2-0883-4361-f2c7-609b35d56192"
      },
      "source": [
        "!/content/src/alex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nstreams 1ELAPSED TIME: 758.375\n",
            "Nstreams 2ELAPSED TIME: 435.611\n",
            "Nstreams 3ELAPSED TIME: 373.12\n",
            "Nstreams 4ELAPSED TIME: 349.3\n",
            "Nstreams 5ELAPSED TIME: 356.406\n",
            "Nstreams 6ELAPSED TIME: 355.278\n",
            "Nstreams 7ELAPSED TIME: 355.314\n",
            "Nstreams 8ELAPSED TIME: 352.136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqPxQCBihy44"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
